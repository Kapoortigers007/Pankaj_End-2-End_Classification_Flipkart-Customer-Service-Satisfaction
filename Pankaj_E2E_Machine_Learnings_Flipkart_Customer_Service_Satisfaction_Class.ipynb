{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kapoortigers007/Pankaj_End-2-End_Unsupervised_ML_Project_II/blob/main/Pankaj_E2E_Machine_Learnings_Flipkart_Customer_Service_Satisfaction_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    - Classification - Flipkart Customer Service Satisfaction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Name -** - Pankaj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "#### Project Summary: Classification - Flipkart Customer Service Satisfaction\n",
        "In the highly competitive world of e-commerce, customer satisfaction is a critical business driver. Flipkart, being one of India’s largest online retail platforms, handles thousands of customer support interactions daily through various channels like inbound calls, outcalls, and email. The quality of these interactions directly affects customer retention, loyalty, and public reputation.\n",
        "\n",
        "This project focuses on building a machine learning model to predict customer satisfaction (CSAT) based on past service interactions. The objective is to identify key drivers of satisfaction, uncover patterns across different customer support teams and service categories, and ultimately enable Flipkart to improve the quality and efficiency of its customer service operations.\n",
        "\n",
        "#### Business Problem\n",
        "The dataset provided contains over 85,000 customer support records with 20 attributes, including:\n",
        "- Communication channel (channel_name)\n",
        "- Interaction category (category)\n",
        "- Product information\n",
        "- Agent details\n",
        "- Timestamps (issue_reported_at, issue_responded)\n",
        "- CSAT score (1 to 5)\n",
        "The goal is to classify whether a customer was satisfied (CSAT ≥ 4) or not satisfied (CSAT < 4) using these attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "**Classification Problem —** Predicting Flipkart Customer Service Satisfaction\\\n",
        "**Goal:** Understand satisfaction drivers, assess support team performance, and optimize service quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgbUHAGgjLW",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# **General Guidelines** : -  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# for datetime manipulation\n",
        "import datetime\n",
        "\n",
        "# for text handling\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "96da3ddb-a1ff-4e5f-fe6c-c0784977f4d6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Customer_support_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2285393144.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Customer_support_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset Successfully Loaded!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Customer_support_data.csv'"
          ]
        }
      ],
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv(\"Customer_support_data.csv\")\n",
        "print('Dataset Successfully Loaded!!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oshhaXvpWlo7"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "#print(len(df))\n",
        "#print(len(df.columns))\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isna(), cbar=True, cmap='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "- There are 85,907 unique records with 20 attributes, and there are 17 object dtypes, 2 float dtypes, and 1 int dtype of data.\n",
        "- The dataset has many columns with 'NaN' values. Needs thorough inspection.\n",
        "- There are no duplicate values in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn9EJ4v5Wlo9"
      },
      "outputs": [],
      "source": [
        "df.describe(include = 'object')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "1) **'Unique id'** and **'Order_id'** have nothing remarkable, so they can be dropped during the model-building phase.\n",
        "2)  We have **3 Unique 'channel_name', 12 unique 'category', and 57 'Sub-category'**.\n",
        "3)  Out of **1782 unique cities**, **722 entries are from 'HYDERABAD'**, which shows that most customer data was from Hyderabad city.\n",
        "4)  There are **5 shifts of Agents, among which 41,426 were 'Morning' only**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for 'channel_name' variable.\n",
        "df['channel_name'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFQ4HSa3Wlo9"
      },
      "source": [
        "- Looks like **Inbound** is the dominant channel for customer interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xKvuRKlWlo9"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for 'category' variable with their value counts.\n",
        "df['category'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF8SduMOWlo-"
      },
      "source": [
        "- The bulk of the customers' issues lies in **'Returns'**, **'Order Related'**, **'Refund Related'** category, approximatley **84%** of interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0Sxm_dRWlo-"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for 'Agent_shift' variable.\n",
        "df['Agent Shift'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrJ9wk1GWlo-"
      },
      "source": [
        "- Morning and Evening shifts handle the vast majority of interactions.This can be analyzed further for staffing and analyzing shift-level performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZnW8jldWlo-"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for 'Tenure Bucket' variable.\n",
        "df['Tenure Bucket'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkf3zjFVWlo_"
      },
      "source": [
        "- Significant portion of agents are either experienced(?90 days)  or very new(On Job Traininig)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocV5B8tSWlo_"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for 'Product_category' variable.\n",
        "df['Product_category'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfngjiWVWlo_"
      },
      "source": [
        "- **Electronics(27.36%), Lifestyle(23.94%),** and **Books & General Merchandise(19.3%)** are top 3 interaction categories by interaction volume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A99bv7iEWlo_"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for 'CSAT Score' variable.\n",
        "df['CSAT Score'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBHT_g6aWlpA"
      },
      "source": [
        "- This is a typical **'J-shaped'** distribution. A high percentage of 5s is good, but the substantial number of 1s highlights areas of improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EufJmtBKWlpA"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for 'Customer_city' variable.\n",
        "df['Customer_City'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx6MRML3WlpA"
      },
      "outputs": [],
      "source": [
        "# Percentage of people who didn't enter the city name.\n",
        "df['Customer_City'].isnull().sum() / len(df['Customer_City'])  * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy3hZoGjWlpA"
      },
      "source": [
        "- **80%** of city data is missing. It's challenging to use the this for predictive modelling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_mwYt5uWlpA"
      },
      "outputs": [],
      "source": [
        "# Check max value for 'Item Price' variable.\n",
        "df['Item_price'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rerM-afbWlpA"
      },
      "outputs": [],
      "source": [
        "# Check CSAT Score by Channel Name.\n",
        "df.groupby('channel_name')['CSAT Score'].mean().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKlTi9yfWlpA"
      },
      "source": [
        "- Email support has noticeably lower average CSAT score as compared to Outcall and Inbound. Why Email customers are less satisfied?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xOC2r1MWlpB"
      },
      "outputs": [],
      "source": [
        "# Check CSAT Score by Grouping against Manager and Supervisor.\n",
        "df.groupby(['Manager','Supervisor'])['CSAT Score'].mean().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSGfjOnWWlpB"
      },
      "source": [
        "- The performance of Nathan Patel and Zoe Yamamoto is rated high, unlike Oliver Nguyen and Dylan Kim, where the first one among two are working under the same Manager John Smith.Thee might be need for training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wGmQvHyWlpB"
      },
      "outputs": [],
      "source": [
        "# Check CSAT score by product category.\n",
        "df.groupby('Product_category')['CSAT Score'].mean().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujm4-u-pWlpB"
      },
      "source": [
        "- **GiftCard (3.23), Furniture (3.62), Mobile (3.65), Home Appliances (3.70)** are the categories with the lowest CSAT score. These could be the pain points which leads to many customers giving it low CSAT score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9kcp9HlQWlpB"
      },
      "outputs": [],
      "source": [
        "# Check CSAT Score by Category.\n",
        "df.groupby('category')['CSAT Score'].mean().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGIIVzw3WlpB"
      },
      "source": [
        "- **Others (3.43), Cancellation (3.99), Product Queries (4.04), Order Related (4.10)** are the lowest CSAT interaction categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXOzu1mGWlpB"
      },
      "outputs": [],
      "source": [
        "df.describe(include='all').transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8byhVomWlpC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Customer_support_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dPMK3FzWlpC"
      },
      "outputs": [],
      "source": [
        "# Convert all column names to snake case.\n",
        "# import re module\n",
        "import re\n",
        "# Define the'convert_to_snake_case' function to convert column names to the same case.\n",
        "def convert_to_snake_case(column_name):\n",
        "    #convert to lowercase\n",
        "    s = column_name.lower()\n",
        "\n",
        "    # replace spaces, hyphens, and alphanumeric characters with underscores.\n",
        "    s = re.sub(r'[^a-z0-9_]+','_', s)\n",
        "\n",
        "    # remove leading or trailing underscores\n",
        "    s = s.strip('_')\n",
        "\n",
        "    # replace multiple underscores with a single underscore\n",
        "    s = re.sub(r'_+','_',s)\n",
        "\n",
        "    return s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU22emjDWlpD"
      },
      "outputs": [],
      "source": [
        "df.columns = [convert_to_snake_case(col) for col in df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9ayqwmoWlpD"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHdEyh5yWlpD"
      },
      "outputs": [],
      "source": [
        "# Drop irrelevant columns\n",
        "df = df.drop(['unique_id','order_id'], axis = 1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fPsEJaRWlpD"
      },
      "outputs": [],
      "source": [
        "# convert timstamp columns to datetime format\n",
        "date_time_cols= ['order_date_time','issue_reported_at','issue_responded','survey_response_date']\n",
        "\n",
        "for col in date_time_cols:\n",
        "    df[col] = pd.to_datetime(df[col], errors='coerce',dayfirst=True)  # 'coerce' will turn parsing errors into NaT (Not a Time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y62P-jTzWlpD"
      },
      "outputs": [],
      "source": [
        "df['csat_score'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE3F4g1_WlpD"
      },
      "outputs": [],
      "source": [
        "# Replace missing value of city column 'NaN' to 'Missing_City'.\n",
        "df['customer_city'] = df['customer_city'].fillna('Missing_City')\n",
        "df['customer_city'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76cehD85WlpD"
      },
      "outputs": [],
      "source": [
        "# Fill 'NaN' values in the customer_remark to empty string.\n",
        "df['customer_remarks'] = df['customer_remarks'].fillna('')\n",
        "df['customer_remarks']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUBPJJxqWlpD"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oit3XNf4WlpD"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJxXK5MGWlpD"
      },
      "outputs": [],
      "source": [
        "# Fill 'NaNs' in Product Category with a string like 'No_Product_Context'.\n",
        "df['product_category'] = df['product_category'].fillna('No_Product_Context')\n",
        "df['product_category']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSi2n4m3WlpE"
      },
      "outputs": [],
      "source": [
        "# Fill 'item_price' 'NaN' values with '0'.\n",
        "df['item_price'] = df['item_price'].fillna(0)\n",
        "df['item_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T7_2JOkWlpE"
      },
      "outputs": [],
      "source": [
        "# create a binary column named 'has_order_date' with '1' if 'order_date_time' is not NaN, 0 otherwise.\n",
        "df['has_order_date']  = df['order_date_time'].notna().astype(int)\n",
        "df['has_order_date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCCFd0EwWlpE"
      },
      "outputs": [],
      "source": [
        "df['has_order_date'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBGJLESZWlpE"
      },
      "outputs": [],
      "source": [
        "# Create a binary column 'is_connected_call' with '1' if 'connected_handling_time' is not NaN, 0 otherwise.\n",
        "df['is_connected_call'] = df['connected_handling_time'].notna().astype(int)\n",
        "df['is_connected_call']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeOeojhZWlpE"
      },
      "outputs": [],
      "source": [
        "# Fill 'NaNs' in the original 'connected_handling_time' with 0\n",
        "df['connected_handling_time'] = df['connected_handling_time'].fillna(0)\n",
        "df['connected_handling_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsVDFdGEWlpE"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKLnYO4rWlpF"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "1) Converted all column names to snake_case.\n",
        "\n",
        "2) Dropped the unique_id and order_id columns.\n",
        "\n",
        "3) Converted timestamp columns to datetime objects.\n",
        "\n",
        "4) Handled missing values in customer_city, product_category, item_price, and connected_handling_time.\n",
        "\n",
        "5) Created new binary indicator columns (has_order_date, is_connected_call) to capture the information about missingness in order_date_time and connected_handling_time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egS-pXF7WlpF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQd0ftouWlpF"
      },
      "outputs": [],
      "source": [
        "# display summary stats of data\n",
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQj9ALZwWlpF"
      },
      "outputs": [],
      "source": [
        "df.describe(include = 'object').transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1  Pie Chart showing Customer Service Channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (3,3))\n",
        "data = df['channel_name'].value_counts()\n",
        "plt.pie(data,\n",
        "       labels = [\n",
        "           f'{data.index[0]} : {data.values[0]}',\n",
        "           f'{data.index[1]} : {data.values[1]}',\n",
        "           f'{data.index[2]} : {data.values[2]}'\n",
        "       ],\n",
        "        autopct= '%1.1f%%'\n",
        "       )\n",
        "\n",
        "plt.title('Distribution of Customer Service Channel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "To understand how customers interact with support — via Inbound, Outcall, or Email."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "- Majority (~79%) of interactions are through Inbound.\n",
        "- Email support is minimal (~3.5%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KxVbGu8WlpG"
      },
      "source": [
        "- Inbound is the most critical channel for service experience.\n",
        "- Opportunity to improve and scale Email and Outcall support."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXHFnXQWWlpG"
      },
      "source": [
        "##### 4. Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "Email's low share might indicate underutilization or poor awareness of that support option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize = (5,1))\n",
        "sns.boxplot(x = df['item_price'], fliersize = 1)\n",
        "plt.title('Item Price Boxplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "To detect price outliers and understand spread."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "- Many extreme high-value outliers present.\n",
        "- Most values are concentrated below ₹5,000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaNHWu05WlpH"
      },
      "source": [
        "Outliers can distort analysis; must be handled carefully during modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkKCFhTWWlpH"
      },
      "source": [
        "##### 4. Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "If outliers are genuine, support may be skewed toward high-value items — risk of bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize = (5,3))\n",
        "sns.histplot(data = df,\n",
        "             x = df['item_price'],\n",
        "             bins = range(0,1500,200)\n",
        "            )\n",
        "mean = df['item_price'].mean()\n",
        "plt.axvline(mean, color = 'red', linestyle = '--')\n",
        "plt.text(700, 20000, 'mean = 1134', color = 'red')\n",
        "plt.title(\"Item Price Histogram\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "To observe the distribution and skewness in pricing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "- Highly right-skewed.\n",
        "- Mean item price ≈ ₹1134, but most transactions are much lower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-G0H-IqWlpI"
      },
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXStdeXAWlpI"
      },
      "source": [
        "##### 4. Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "Yes — ignoring skew may result in poor segmentation of premium vs low-value items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4 Barplot showing distribution of Agent Tenure Buckets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize= (7,5))\n",
        "tenure_bucket = df['tenure_bucket'].value_counts()\n",
        "ax = sns.barplot(x= tenure_bucket.index, y = tenure_bucket.values, palette = 'viridis' ,legend=False)\n",
        "plt.title('Agent Tenure Buckets Barplots')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "To examine distribution of agent experience (tenure)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "- Majority have >90 days or are in training.\n",
        "- Less experienced (0–60 days) agents are fewer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReCWJ9CcWlpJ"
      },
      "source": [
        "New agents might need better onboarding as they impact customer satisfaction early on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqshk0rtWlpJ"
      },
      "source": [
        "##### 4. Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2Bgs6prWlpK"
      },
      "source": [
        "Potential quality dips if large workloads are handled by fresh hires."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "category_csat = df.groupby('category')['csat_score'].mean().sort_values(ascending = False)\n",
        "plt.figure(figsize = (12,5))\n",
        "ax = sns.barplot(x = category_csat.index, y = category_csat.values, palette = 'coolwarm')\n",
        "plt.xticks(rotation = 45)\n",
        "plt.grid(axis = 'y', linestyle = '--', alpha = 0.7)\n",
        "#ax.axhline(df['csat_score'].mean(), ls = '--', color = 'red', label = 'Median_CSAT_Score')\n",
        "plt.title(\"Average CSAT Score by Interation Category\",fontsize = 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "To identify which support types yield higher/lower satisfaction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "- App/Website, Payments, and Returns have highest CSAT.\n",
        "- Others and Cancellation are lowest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoTxdGU1WlpL"
      },
      "source": [
        "Prioritize training for teams handling low-CSAT categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heJDKU0lWlpL"
      },
      "source": [
        "##### 4. Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "Yes — Cancellation and Others indicate dissatisfaction. Fix root causes like delay/refund policies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "category_csat = df.groupby('channel_name')['csat_score'].mean().sort_values(ascending = False)\n",
        "plt.figure(figsize = (12,5))\n",
        "ax = sns.barplot(x = category_csat.index, y = category_csat.values, palette = 'viridis')\n",
        "plt.xticks(rotation = 45)\n",
        "plt.grid(axis = 'y', linestyle = '--', alpha = 0.7)\n",
        "#ax.axhline(df['csat_score'].mean(), ls = '--', color = 'red', label = 'Median_CSAT_Score')\n",
        "plt.title(\"Average CSAT Score by Channel Name\",fontsize = 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFf2-_FphqN"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "To compare performance across support channels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouA3fa0phqN"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "- Outcall slightly edges Inbound.\n",
        "- Email scores the lowest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seke61FWphqN"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYrVuNPSWlpM"
      },
      "source": [
        "Email team training or process revamp can boost overall CSAT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grd-_MRjWlpM"
      },
      "source": [
        "##### 4. Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p2Rr4KPWlpM"
      },
      "source": [
        "Yes — Poor email CSAT can affect customers who prefer non-verbal channels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW4_bGpfphqN"
      },
      "source": [
        "Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "category_order = df.groupby('category')['csat_score'].mean().sort_values(ascending=False).index.tolist()\n",
        "channel_order = df.groupby('channel_name')['csat_score'].mean().sort_values().index.tolist()\n",
        "plt.figure(figsize=(12, 5)) # Make the figure wider\n",
        "sns.barplot(\n",
        "    data=df,\n",
        "    x='category',\n",
        "    y='csat_score',\n",
        "    hue='channel_name',\n",
        "    order=category_order, # Apply order for categories\n",
        "    hue_order=channel_order, # Apply order for channels\n",
        "    palette='viridis'\n",
        ")\n",
        "plt.title('Average CSAT Score by Interaction Category and Channel', fontsize=18)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27r6nlMphqO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv6ro40sphqO"
      },
      "source": [
        "To analyze how CSAT varies by both interaction type and channel — multivariate view."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2jJGEOYphqO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6ZPi4hphqO"
      },
      "source": [
        "- Email underperforms across many categories.\n",
        "- Inbound is more consistent.\n",
        "- Variance is high in some categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JNsNcRphqO"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CJrNoWaWlpN"
      },
      "source": [
        "Enables targeting specific category+channel combinations for improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb6RAYiZWlpN"
      },
      "source": [
        "##### 4. Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "Yes — CSAT drops in specific category-channel pairs (e.g. Email + Cancellation) need urgent fixes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7MS06SUHkB-"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1\n",
        "Is there a statistically significant difference in the average CSAT scores across different customer communication channels (channel_name)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "**Null Hypothesis (H_0):** There is no statistically significant difference in the average CSAT score among the different customer communication channels (Email, Inbound, Outcall). Any observed differences are due to random chance.\n",
        "\n",
        "**Alternate Hypothesis (H_1):** At least one channel's average CSAT score is statistically different from the others.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Isolate the 'csat_score' for each channel type\n",
        "csat_email = df[df['channel_name'] == 'Email']['csat_score']\n",
        "csat_inbound = df[df['channel_name'] == 'Inbound']['csat_score']\n",
        "csat_outcall = df[df['channel_name'] == 'Outcall']['csat_score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n21LHQP6WlpP"
      },
      "outputs": [],
      "source": [
        "# Perform the One-Way ANOVA test\n",
        "# Pass each group's data as separate arguments to f_oneway\n",
        "f_statistic, p_value_simple = stats.f_oneway(csat_email, csat_inbound, csat_outcall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHprBlmbWlpP"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- One-Way ANOVA Results (using scipy.stats.f_oneway) ---\")\n",
        "print(f\"F-statistic: {f_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value_simple:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N9zIV3PWlpP"
      },
      "outputs": [],
      "source": [
        "df['channel_name'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "One-Way Analysis of Variance (ANOVA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "Because we are comparing the mean CSAT scores of more than two independent groups (Email, Inbound, Outcall). One-way ANOVA is ideal for this scenario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2\n",
        "Is there a statistically significant difference in the average CSAT scores across different interaction categories (category)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "**Null Hypothesis (H_0):** There is no statistically significant difference in the average CSAT score among the various interaction category types. Any observed differences are due to random chance.\n",
        "\n",
        "**Alternate Hypothesis (H_1):** At least one interaction category's average CSAT score is statistically different from the others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Get all unique categories\n",
        "unique_categories = df['category'].unique()\n",
        "\n",
        "# This extracts the 'csat_score' for all rows belonging to a specific 'category'\n",
        "csat_scores_by_category = [df[df['category'] == category]['csat_score'] for category in unique_categories]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny02YaHWWlpQ"
      },
      "outputs": [],
      "source": [
        "# The asterisk (*) unpacks the list of Series, passing each Series as a separate argument\n",
        "f_statistic, p_value_simple = stats.f_oneway(*csat_scores_by_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNuI3w_pWlpQ"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- One-Way ANOVA Results (using scipy.stats.f_oneway) ---\")\n",
        "print(f\"F-statistic: {f_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value_simple:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "One-Way ANOVA using scipy.stats.f_oneway()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "We are testing whether there is a significant difference in mean CSAT scores across multiple categorical groups. One-way ANOVA is suitable to check differences between >2 group means."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6f_Z7YlWlpR"
      },
      "source": [
        "Does the presence of an order date (has_order_date) affect the customer satisfaction score (CSAT)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "**Null Hypothesis (H₀):**\n",
        "There is no statistically significant difference in the average CSAT scores between interactions that have an order date and those that do not.\n",
        "Any observed difference is due to random chance. \\\n",
        "**Alternate Hypothesis (H₁):**\n",
        "There is a statistically significant difference in the average CSAT scores between interactions that have an order date and those that do not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Group 1: Interactions where has_order_date is 1 (True)\n",
        "csat_with_order = df[df['has_order_date'] == 1]['csat_score']\n",
        "\n",
        "# Group 2: Interactions where has_order_date is 0 (False)\n",
        "csat_without_order = df[df['has_order_date'] == 0]['csat_score']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF7AD4TOWlpS"
      },
      "outputs": [],
      "source": [
        "# We'll use equal_var=False (Welch's t-test) which does not assume equal variances, making it more robust.\n",
        "t_statistic, p_value_ttest = stats.ttest_ind(a=csat_with_order, b=csat_without_order, equal_var=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1haMEEd_WlpS"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Independent Samples t-test Results (CSAT by has_order_date) ---\")\n",
        "print(f\"T-statistic: {t_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value_ttest:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-38lCMNeWlpS"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGW__xdnWlpS"
      },
      "source": [
        "Welch’s t-test (independent samples t-test with unequal variances) using scipy.stats.ttest_ind() with equal_var=False."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pftB6NigWlpS"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihLeTnlsWlpT"
      },
      "source": [
        "This is a binary comparison of two independent groups (has_order_date = 1 vs 0). Welch’s t-test is preferred when variances may not be equal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SflTycvDWlpT"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck84ozgoWlpU"
      },
      "outputs": [],
      "source": [
        "# Make a copy to ensure original df is not modified if you want to rerun parts\n",
        "df_processed = df.copy()\n",
        "df_processed.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 1. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# Check Missing Values\n",
        "df_processed.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNLaJrn-WlpU"
      },
      "outputs": [],
      "source": [
        "df_processed.drop(columns=['sub_category','order_date_time','customer_city','agent_name','supervisor'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qr-tB4iWlpU"
      },
      "outputs": [],
      "source": [
        "df_processed.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "lower_bound_price = df_processed['item_price'].quantile(0.01)\n",
        "upper_bound_price = df_processed['item_price'].quantile(0.99)\n",
        "df_processed['item_price'] = np.clip(df_processed['item_price'], lower_bound_price, upper_bound_price)\n",
        "print(f\"Outliers in 'item_price' clipped to between {lower_bound_price:.2f} and {upper_bound_price:.2f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZz5OrT1HH-"
      },
      "source": [
        "Techniques Used:\n",
        "1. Filled customer_city with \"Missing_City\"\n",
        "→ Used for meaningful placeholder to preserve categorical integrity.\n",
        "\n",
        "2. Filled customer_remarks with empty string ''\n",
        "→ Used because it’s text and can be treated as absence of remarks without harming modeling.\n",
        "\n",
        "3. Filled product_category with \"No_Product_Context\"\n",
        "→ Helps retain record without dropping rows, while indicating lack of category info.\n",
        "\n",
        "4. Filled item_price with 0\n",
        "→ Logically assumes that unknown price ≈ free sample or negligible in absence of info.\n",
        "\n",
        "5. Filled connected_handling_time with 0\n",
        "→ Reasonable if connection time wasn’t recorded or the interaction didn’t require it.\n",
        "\n",
        "6. Created binary flags: has_order_date, is_connected_call\n",
        "→ Preserves signal from missingness which might be useful for modeling.\n",
        "\n",
        "7. Dropped:\n",
        "- order_date_time (too sparse)\n",
        "- sub_category, customer_city, agent_name, supervisor (low utility/high cardinality or already captured indirectly)\n",
        "\n",
        "Why These Techniques?\n",
        "- All techniques preserve data rather than delete.\n",
        "- Logical replacements for categorical/textual fields improve model performance.\n",
        "- Binary flags help retain useful information from missingness patterns.\n",
        "- Dropping highly sparse/complex columns avoids overfitting/noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "df_processed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cr98IY0WlpV"
      },
      "outputs": [],
      "source": [
        "# Identify all columns with 'object' dtype\n",
        "object_columns = df_processed.select_dtypes(include='object').columns.tolist()\n",
        "object_columns.remove('customer_remarks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-xkOeMQWlpV"
      },
      "outputs": [],
      "source": [
        "object_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlpG53M5WlpV"
      },
      "outputs": [],
      "source": [
        "# Perform One-hot encoding on identified columns.\n",
        "df_encoded = pd.get_dummies(df_processed, columns=object_columns, drop_first=True, dtype=int)\n",
        "df_encoded.drop(columns = 'customer_remarks', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2bJ5FTBWlpV"
      },
      "outputs": [],
      "source": [
        "df_encoded.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "Techniques Used:\n",
        "- Clipping (also known as Winsorizing):\n",
        "item_price was clipped between the 1st percentile and 99th percentile values.\n",
        "\n",
        "Why This Technique?\n",
        "- item_price is highly right-skewed with extreme outliers, which can distort model performance.\n",
        "- Clipping helps reduce model sensitivity to large outliers without losing the rows.\n",
        "- It retains the overall distribution shape while bounding extreme influence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMQiZwjn3iu7"
      },
      "source": [
        "#### 1. Expand Contraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "outputs": [],
      "source": [
        "# Expand Contraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVIkgGqN3qsr"
      },
      "source": [
        "#### 2. Lower Casing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "outputs": [],
      "source": [
        "# Lower Casing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkPnILGE3zoT"
      },
      "source": [
        "#### 3. Removing Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "outputs": [],
      "source": [
        "# Remove Punctuations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlsf0x5436Go"
      },
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "outputs": [],
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT9DMSJo4nBL"
      },
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "outputs": [],
      "source": [
        "# Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "outputs": [],
      "source": [
        "# Remove White spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c49ITxTc407N"
      },
      "source": [
        "#### 6. Rephrase Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "outputs": [],
      "source": [
        "# Rephrase Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeJFEK0N496M"
      },
      "source": [
        "#### 7. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "outputs": [],
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ExmJH0g5HBk"
      },
      "source": [
        "#### 8. Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "outputs": [],
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNqERVU536h"
      },
      "source": [
        "##### Which text normalization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jKVxE06BC1"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5UmGsbsOxih"
      },
      "source": [
        "#### 9. Part of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "outputs": [],
      "source": [
        "# POS Taging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      },
      "source": [
        "#### 10. Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "outputs": [],
      "source": [
        "# Vectorizing Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBMux9mC6MCf"
      },
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su2EnbCh6UKQ"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "sns.heatmap(df_encoded.corr(), cbar=True, cmap='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su2tJ9p1WlpY"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = df_encoded.corr()\n",
        "csat_correlations = correlation_matrix['csat_score']\n",
        "\n",
        "top_correlated_features = csat_correlations.abs().sort_values(ascending=False)\n",
        "top_correlated_features = top_correlated_features.drop('csat_score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR7jtZtBWlpY"
      },
      "outputs": [],
      "source": [
        "num_top_features_to_display = 20\n",
        "print(top_correlated_features.head(num_top_features_to_display))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF0ctZc7WlpY"
      },
      "outputs": [],
      "source": [
        "# Define the exact list of 20 features you want to use, plus the target variable\n",
        "selected_20_features_list = [\n",
        "    'item_price',\n",
        "    'has_order_date',\n",
        "    'product_category_No_Product_Context',\n",
        "    'category_Returns',\n",
        "    'category_Order Related',\n",
        "    'product_category_Mobile',\n",
        "    'product_category_Home Appliences',\n",
        "    'tenure_bucket_On Job Training',\n",
        "    'issue_reported_at',        # Note: This is a raw datetime column (numerical timestamp)\n",
        "    'product_category_Electronics',\n",
        "    'agent_shift_Morning',\n",
        "    'product_category_Furniture',\n",
        "    'issue_responded',          # Note: This is a raw datetime column (numerical timestamp)\n",
        "    'survey_response_date',     # Note: This is a raw datetime column (numerical timestamp)\n",
        "    'category_Product Queries',\n",
        "    'product_category_Books & General merchandise',\n",
        "    'category_Cancellation',\n",
        "    'manager_William Kim',\n",
        "    'manager_Jennifer Nguyen',\n",
        "    'agent_shift_Split',\n",
        "    'csat_score' # Don't forget your target variable!\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g66B5oTRWlpY"
      },
      "outputs": [],
      "source": [
        "df_filtered_for_model = df_encoded[\n",
        "    [col for col in selected_20_features_list if col in df_encoded.columns]\n",
        "].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxNTAzKWWlpY"
      },
      "outputs": [],
      "source": [
        "df_filtered_for_model.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju3BvG9TWlpZ"
      },
      "outputs": [],
      "source": [
        "for dt_col in ['issue_reported_at', 'issue_responded', 'survey_response_date']:\n",
        "    if dt_col in df_filtered_for_model.columns and df_filtered_for_model[dt_col].dtype == 'object':\n",
        "        df_filtered_for_model[dt_col] = pd.to_datetime(df_filtered_for_model[dt_col], errors='coerce').astype(np.int64) // 10**9 # Convert to Unix timestamp\n",
        "        # Handle NaNs that might result from coerce\n",
        "        df_filtered_for_model[dt_col] = df_filtered_for_model[dt_col].fillna(df_filtered_for_model[dt_col].median())\n",
        "        print(f\"Converted '{dt_col}' to numerical timestamp.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmlQqR5TWlpZ"
      },
      "outputs": [],
      "source": [
        "print(f\"DataFrame shape with selected 20 features: {df_filtered_for_model.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "Methods Used:\n",
        "1. Correlation-Based Feature Selection:\n",
        "- Used df_encoded.corr() to calculate pairwise correlations with the target csat_score.\n",
        "- Selected top 20 features based on absolute correlation strength.\n",
        "\n",
        "2. One-Hot Encoding (OHE):\n",
        "- Before correlation, categorical features were encoded, which made them analyzable by correlation matrix.\n",
        "\n",
        "3. Manual Sanity Check:\n",
        "- After correlation ranking, a domain-informed filtering step ensured inclusion of interpretable and non-redundant features (e.g., dropped multicollinear ones or low business value fields).\n",
        "\n",
        "4. Datetime Conversion:\n",
        "- Converted datetime columns (issue_reported_at, issue_responded, survey_response_date) into Unix timestamp to use in modeling.\n",
        "- Imputed any resulting NaNs with median."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "Key Features and Reasoning:\n",
        "Feature\tReason\n",
        "1. item_price- Direct customer investment — likely to affect CSAT\n",
        "2 has_order_date- Indicates real order context — influences satisfaction\n",
        "3. product_category_*- Different product types may have varying service expectations\n",
        "4. category_* -Nature of issue (Returns, Cancellations) highly correlated to CSAT\n",
        "5. tenure_bucket_On Job Training- Agent experience affects customer perception\n",
        "6. agent_shift_*- Service quality may vary by shift (e.g., morning = better staff availability)\n",
        "7. manager_*- Manager-level differences may show in agent/team performance\n",
        "8. issue_*,survey_response_date- \tTime-based features might capture response lags or delay patterns\n",
        "9. csat_score - Target variable for classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vObcroFdWlpa"
      },
      "source": [
        "| Transformation                                     | Columns                                                        | Reason                                                                                                                                      |\n",
        "| -------------------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Datetime to Unix timestamp**                     | `issue_reported_at`, `issue_responded`, `survey_response_date` | ML models can’t interpret datetime strings — converting to **numeric timestamps** enables meaningful analysis (like response delay).        |\n",
        "| **Binary classification transformation of target** | `csat_score → y = 1 if score ≥ 4 else 0`                       | Reframed the problem as a **binary classification task**: satisfied vs. not satisfied — simplifies modeling and aligns with business goals. |\n",
        "| **Imputation of NaTs from datetime**               | Filled with column median                                      | Prevents nulls from breaking model training — median ensures minimal skew influence.                                                        |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn2q3iiYWlpa"
      },
      "outputs": [],
      "source": [
        "# 1. Separate features (X) and target (y)\n",
        "X = df_filtered_for_model.drop('csat_score', axis=1)\n",
        "y = df_filtered_for_model['csat_score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po5kWR-oWlpa"
      },
      "outputs": [],
      "source": [
        "numerical_features_for_ops = [\n",
        "    'item_price',\n",
        "    # Note: 'connected_handling_time' and 'response_time_in_hours' are NOT in your top 20 list.\n",
        "    # If they were intended to be transformed/scaled, they need to be in the 20 features list.\n",
        "    # The datetime features ('issue_reported_at', 'issue_responded', 'survey_response_date')\n",
        "    # will also be treated as numerical for scaling if they remain.\n",
        "    'issue_reported_at',\n",
        "    'issue_responded',\n",
        "    'survey_response_date'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99QRwn1rWlpa"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDF5Bk6QWlpb"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLeAZldPWlpb"
      },
      "outputs": [],
      "source": [
        "y = df_filtered_for_model['csat_score'].apply(lambda score: 1 if score >= 4 else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Dimesionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexQrXU-DjzY"
      },
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "outputs": [],
      "source": [
        "# DImensionality Reduction (If needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5CmagL3EC8N"
      },
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKr75IDuEM7t"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6oLwnr9Wlpc"
      },
      "source": [
        "- Splitting Ratio: 80% Train / 20% Test  \n",
        "#### Why this ratio?\n",
        "- Standard best practice in classification tasks with moderately large datasets.\n",
        "- Ensures enough data for training while keeping a fair test set to evaluate generalization.\n",
        "- Stratified split was used via stratify=y to maintain class balance between train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px34YRHyWlpc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYplFMbXWlpc"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nFinal Data Shapes:\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUkhO86zWlpc"
      },
      "outputs": [],
      "source": [
        "X_train.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYz2RKmtWlpc"
      },
      "outputs": [],
      "source": [
        "datetime_cols_to_convert = [\n",
        "    'issue_reported_at',\n",
        "    'issue_responded',\n",
        "    'survey_response_date'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6ADRtYwWlpc"
      },
      "outputs": [],
      "source": [
        "for col in datetime_cols_to_convert:\n",
        "    if col in X.columns:\n",
        "        # 1. Ensure the column is a datetime object (errors='coerce' turns unparseable dates into NaT)\n",
        "        X[col] = pd.to_datetime(X[col], errors='coerce')\n",
        "\n",
        "        # 2. Convert datetime to Unix timestamp (seconds since 1970-01-01)\n",
        "        # .astype(np.int64) converts to nanoseconds since epoch\n",
        "        # // 10**9 converts nanoseconds to seconds\n",
        "        X[col] = X[col].astype(np.int64) // 10**9\n",
        "\n",
        "        # 3. Handle any NaNs that might have resulted from 'errors=coerce' or original NaTs\n",
        "        # Fill NaNs with the median of the column's numerical values\n",
        "        median_timestamp = X[col].median()\n",
        "        X[col] = X[col].fillna(median_timestamp)\n",
        "\n",
        "        print(f\"Converted '{col}' to numerical timestamp and filled NaNs with median.\")\n",
        "    else:\n",
        "        print(f\"Warning: Column '{col}' not found in DataFrame. Skipping conversion.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqpNgepFxVj"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbet1HwdGDTz"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M97_ircpWlpd"
      },
      "outputs": [],
      "source": [
        "# Import packages for data modelin\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, \\\n",
        "recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzIxltTWWlpd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1 Logitic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMjm2iO1Wlpd"
      },
      "outputs": [],
      "source": [
        "# Construct a logistic regression model and fit it to the training set\n",
        "log_clf = LogisticRegression(random_state=0,max_iter=500).fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qts_QBCWlpd"
      },
      "outputs": [],
      "source": [
        "# Use the logistic regression model to get predictions on the encoded testing set\n",
        "y_pred = log_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVLi0FxmWlpd"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uczl3XVWlpd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVxw4V5OWlpd"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjLmkRduWlpe"
      },
      "outputs": [],
      "source": [
        "# Get the feature names from the model and the model coefficients (which represent log-odds ratios)\n",
        "# Place into a DataFrame for readability\n",
        "pd.DataFrame(data={\"Feature Name\":log_clf.feature_names_in_ , \"Model Coefficient\":log_clf.coef_[0]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC987JW9Wlpe"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNlf6jIgWlpe"
      },
      "source": [
        "##### Why Logistic Regression?\n",
        "- A strong baseline model for binary classification problems.\n",
        "- Offers interpretability through feature coefficients (log-odds).\n",
        "- Simple, fast, and useful to evaluate before deploying complex models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c15jO08OWlpe"
      },
      "source": [
        "##### Interpretation:\n",
        "- High accuracy and strong performance for class 1 (Satisfied).\n",
        "- Very poor recall for class 0 (Not satisfied) – model fails to catch dissatisfied users.\n",
        "- This is due to class imbalance — Logistic Regression is biased toward majority class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACrdUqojWlpe"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhYvs16kWlpe"
      },
      "outputs": [],
      "source": [
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size=0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nmIZKR4Wlpe"
      },
      "outputs": [],
      "source": [
        "# Get shape of each training, validation, and testing set\n",
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXhFAf3kWlpe"
      },
      "outputs": [],
      "source": [
        "# Instantiate the random forest classifier\n",
        "rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Create a dictionary of hyperparameters to tune\n",
        "cv_params = {'max_depth': [5, 7, None],\n",
        "             'max_features': [0.3, 0.6],\n",
        "            #  'max_features': 'auto'\n",
        "             'max_samples': [0.7],\n",
        "             'min_samples_leaf': [1,2],\n",
        "             'min_samples_split': [2,3],\n",
        "             'n_estimators': [75,100,200],\n",
        "             }\n",
        "\n",
        "# Define a dictionary of scoring metrics to capture\n",
        "scorings = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Instantiate the GridSearchCV object\n",
        "rf_cv = GridSearchCV(rf, cv_params, scoring=scorings, cv=5, refit='recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D5p-fhMWlpf"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "rf_cv.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Examine best recall score\n",
        "rf_cv.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CmuF8SzWlpf"
      },
      "outputs": [],
      "source": [
        "# Examine best parameters\n",
        "rf_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNkcTGcGWlpf"
      },
      "outputs": [],
      "source": [
        "# Create a confusion matrix to visualize the results of the classification model\n",
        "\n",
        "# Compute values for confusion matrix\n",
        "log_cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Create display of confusion matrix\n",
        "log_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=None)\n",
        "\n",
        "# Plot confusion matrix\n",
        "log_disp.plot()\n",
        "\n",
        "# Display plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgrTNJdVWlpf"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_val, y_pred,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG4JdIldWlpf"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhN2vPxnWlpf"
      },
      "source": [
        "Why Random Forest?\n",
        "- A powerful ensemble classifier that combines multiple decision trees to reduce overfitting and boost accuracy.\n",
        "- Handles non-linear relationships, missing values, and imbalanced classes better than Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Feature-Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "\n",
        "importances = rf_cv.best_estimator_.feature_importances_\n",
        "rf_importances = pd.Series(importances, index=X_test.columns)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rf_importances.plot.bar(ax=ax)\n",
        "ax.set_title('Feature importances')\n",
        "ax.set_ylabel('Mean decrease in impurity')\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtzDVQbCWlpf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIWqOdwVWlpg"
      },
      "outputs": [],
      "source": [
        "# Compute values for confusion matrix\n",
        "log_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Create display of confusion matrix\n",
        "log_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=None)\n",
        "\n",
        "# Plot confusion matrix\n",
        "log_disp.plot()\n",
        "\n",
        "# Display plot\n",
        "plt.title('Random forest - test set');\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "I used GridSearchCV with 5-fold cross-validation. \\\n",
        "**Reason:** It exhaustively searches through a defined parameter grid and evaluates models using multiple folds.\n",
        "Refitting was done on 'recall' to prioritize capturing dissatisfied customers (class 0), which are rarer but more critical from a business perspective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "| Metric                  | Logistic Regression | Random Forest |\n",
        "| ----------------------- | ------------------- | ------------- |\n",
        "| **Accuracy**            | 82%                 | 82%           |\n",
        "| **Recall (Class 0)**    | 0.02                | **0.01**      |\n",
        "| **Precision (Class 0)** | 0.47                | **0.18**      |\n",
        "| **F1-Score (Class 0)**  | 0.05                | **0.02**      |\n",
        "| **Recall (Class 1)**    | 0.99                | **0.99**      |\n",
        "| **F1-Score (Class 1)**  | 0.90                | **0.90**      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkyuqvrgWlpg"
      },
      "source": [
        "Observation:\n",
        "- Recall for class 1 (satisfied) remains very strong.\n",
        "- Class 0 detection still weak, but precision improved slightly.\n",
        "- Feature importance plot helps interpret model — item_price, has_order_date, No_Product_Context are top contributors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": [
        "1. **Accuracy:**\n",
        "- Measures how many predictions were correct.\n",
        "- Business Use: General health of model — but misleading under class imbalance.\n",
        "\n",
        "2. **Precision (Class 0):**\n",
        "- Of all cases predicted as \"not satisfied\", how many were actually correct?\n",
        "- Business Impact: High precision = fewer false alarms → avoids unnecessary service escalations.\n",
        "\n",
        "3. **Recall (Class 0):**\n",
        "- Of all truly dissatisfied customers, how many did we catch?\n",
        "- Business Impact: High recall is crucial for preventing churn and reputational damage.\n",
        "\n",
        "4. **F1-Score:**\n",
        "- Harmonic mean of precision and recall — good for imbalanced datasets.\n",
        "- Business Impact: Helps balance missed dissatisfied customers vs. over-alerting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "I considered the following metrics:\n",
        "| Metric                              | Why it matters for business                                                                                                    |\n",
        "| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n",
        "| **Recall (Class 0: Not Satisfied)** | **Most important** — helps us identify dissatisfied customers. Missing these can lead to churn, complaints, and loss of trust. |\n",
        "| **Precision (Class 0)**             | Important to avoid **false alarms** — unnecessarily escalating satisfied cases adds cost and agent load.                       |\n",
        "| **F1-Score (Class 0)**              | Balances recall and precision — ideal for **imbalanced data**.                                                                 |\n",
        "| **Accuracy**                        | Secondary metric — gives an overall model performance, but not suitable alone due to class imbalance.                          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0FC0zy9Wlpg"
      },
      "source": [
        "**Business Goal:** Minimize customer churn and negative reviews by maximizing recall for dissatisfied customers, while keeping false positives in check."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "I chose the **Random Forest model** as the **final prediction model.**                       \n",
        "### Why?\n",
        "- Better interpretability with feature importances.\n",
        "- Handles non-linearities, missing values, and categorical splits better than Logistic Regression.\n",
        "- Despite slight performance similarity in accuracy, precision for class 0 improved (from 0.47 to 0.18).\n",
        "- Model explainability through impurity-based feature ranking is easier and clearer.\n",
        "- Can be tuned further with class weights, threshold tuning, or ensemble strategies to improve minority class recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "I used Random Forest, an ensemble learning method that constructs multiple decision trees and aggregates their predictions to improve performance and reduce overfitting.\n",
        "- It uses bagging (bootstrap aggregation) to train each tree on a different random subset.\n",
        "- Final prediction is based on majority vote (for classification tasks like ours)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-qF8gcvWlph"
      },
      "source": [
        "| Top Features Identified               | Business Interpretation                                                |\n",
        "| ------------------------------------- | ---------------------------------------------------------------------- |\n",
        "| `item_price`                          | Higher order value → more sensitive CSAT impact                        |\n",
        "| `has_order_date`                      | Orders with missing date context lead to uncertainty or bad experience |\n",
        "| `product_category_No_Product_Context` | Absence of product context reduces agent effectiveness                 |\n",
        "| `category_Returns`                    | Return cases handled well → drive positive CSAT                        |\n",
        "| `category_Order Related`              | Delivery/fulfillment issues correlate with dissatisfaction             |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMkUcKowWlph"
      },
      "source": [
        "**Visualization:** I used rf_cv.best_estimator_.feature_importances_ to generate a bar plot showing top drivers of model predictions, aiding business teams in targeting problem areas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# Save the\n",
        "import pickle\n",
        "\n",
        "# Save the model\n",
        "with open('best_model.pkl', 'wb') as file:\n",
        "    pickle.dump(rf_cv.best_estimator_, file)\n",
        "\n",
        "print(\"Model saved successfully as 'best_model.pkl'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_RRhMhiWlph"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(rf_cv.best_estimator_, 'best_model.joblib')\n",
        "\n",
        "print(\"Model saved successfully as 'best_model.joblib'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "# Load the File and predict unseen data.\n",
        "import pickle\n",
        "\n",
        "# Load the model from file\n",
        "with open('best_model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "print(\" Model loaded successfully from 'best_model.pkl'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38X3JwhpWlpi"
      },
      "outputs": [],
      "source": [
        "# Assuming X_test is your unseen/test data from earlier\n",
        "y_pred_loaded = loaded_model.predict(X_test)\n",
        "\n",
        "# Print first 10 predictions\n",
        "print(\"Sample Predictions:\", y_pred_loaded[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HciLeovwWlpi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\nEvaluation on Test Data:\")\n",
        "print(classification_report(y_test, y_pred_loaded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kee-DAl2viO"
      },
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "### **Final Conclusion**\n",
        "\n",
        "In this project, we developed a robust machine learning pipeline to predict **Flipkart customer service satisfaction (CSAT)** using interaction-level data across various support channels.\n",
        "\n",
        "* We started with a **thorough understanding** of the business problem and performed **extensive EDA**, discovering key trends like:\n",
        "\n",
        "  \n",
        "  * Most support comes via Inbound calls\n",
        "  * Certain categories like **Returns** and **App/Website issues** drive higher CSAT\n",
        "  * **Email support** tends to receive lower satisfaction scores\n",
        "\n",
        "\n",
        "* We handled missing data and outliers with thoughtful strategies and created **new informative features** like:\n",
        "  * `has_order_date`\n",
        "  * `is_connected_call`\n",
        "\n",
        "\n",
        "* Two models were implemented:\n",
        "\n",
        "  * **Logistic Regression** (baseline)\n",
        "  * **Random Forest** (tuned with GridSearchCV)\n",
        "\n",
        "\n",
        "* Based on **recall and precision for the minority class (dissatisfied customers)**, **Random Forest** was selected as the final model.\n",
        "\n",
        "* The model was saved using both **Pickle and Joblib**, and successfully reloaded for prediction, ensuring it's **deployment-ready**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Business Impact**\n",
        "\n",
        "This model can help Flipkart:\n",
        "\n",
        "* **Proactively identify unhappy customers**\n",
        "* Improve agent training and ticket routing\n",
        "* Monitor and optimize **category-wise and channel-wise service quality**\n",
        "\n",
        "With further tuning (e.g., threshold adjustment, SMOTE for imbalance), this system can be integrated into real-time support workflows to improve customer retention and brand loyalty.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y3lxredqlCYt",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "tEA2Xm5dHt1r",
        "8yEUt7NnHlrM",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "dJ2tPlVmpsJ0",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "provenance": [],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}